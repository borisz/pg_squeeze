Release 1.1.2
=============

Bug fixes
---------

1. Adapted the code to changed API of PostgreSQL core code.

   Signature of NewHeapCreateToastTable() changed in PostgreSQL versions
   greater than 11.13.


Release 1.1.1
=============

Bug fixes
---------

1. Fixed failure to find equality operator for index scan. The failure was
   observed when the column type (e.g. varchar) differed from the operator
   class input type (e.g. text).

2. Use index reloptions in the correct format when creating indexes on the new
   table. The bug could cause crash, however it should not lead to corruption
   of the original reloptions since the new catalog entries are eventually
   dropped (only storage of the new index is used).


Release 1.1.0
=============

New features
------------

1. Instead of configuring "first_check" and "task_interval", administrator now
   passes a "schedule" array of timestamps at which table should be squeezed.

2. Table no longer needs to have the user_catalog_table storage option set
   before it can be passed to squeeze_table() function.

   Now INSERT ... ON CONFLICT ... command no longer raises ERROR if trying to
   access table that is just being squeezed. Another advantage is this change
   is that calls of the squeeze_table() function are now easier.

3. No longer disable autovacuum for the table being squeezed.

   The additional code complexity is probably not worth and it does not stop
   already running VACUUM. It's responsibility of the DBA not to allow VACUUM
   to waste resources on a table which should be treated by pg_squeeze.


Bug fixes
---------

1. Close pg_class relation and its scan if exiting early (i.e. catalog change
   was detected).

2. Defend against race conditions that allow for applying of the concurrent
   changes which have already been captured by the initial load. In such a
   case the squeeze_table() function can raise ERROR due to attempt to insert
   duplicate value of identity key, or due to failure to update or delete row
   that no longer exists.

3. Use the correct snapshot for the initial load.

   So far the squeeze_table() function could have used an obsolete snapshot if
   some transaction(s) started after the snapshot builder reached
   SNAPBUILD_FULL_SNAPSHOT state and committed before
   SNAPBUILD_CONSISTENT. Both the initial load and the logical decoding used
   to miss such transactions.

   This problem could only happen after the bug fix #2 had been
   implemented. Before that at least the logical decoding captured the
   problematic transactions because it (the decoding) started earlier than
   necessary.

   No data loss was reported so far, but we still recommend you to upgrade
   pg_squeeze to the version that includes this fix.

4. Do not use "initial load memory context" to fetch tuples from table or
   index.

   If the load takes place in multiple "batches" (i.e. tuplesort is not used),
   that memory context gets freed before the next batch starts and the call fo
   squeeze_table() function results in SEGFAULT.

5. Do not close relation cache entry for index if some field is yet to be
   accessed.

6. Include composite types in the checks of concurrent catalog changes. If
   table has a column of a composite data type and the type is altered during
   the squeeze, the squeeze_table() function raises ERROR.


Release 1.0.1
=============

Bug fixes
---------

1. Try harder to avoid out-of-memory conditions during the initial table load.
